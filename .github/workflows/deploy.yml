# ── Rating Platform — Build, Push & Deploy (ECS Fargate) ─────────────────────
#
# Triggers:
#   - Manual dispatch only → choose environment (dev / staging / prod)
#
# GitHub Secrets required (Settings > Secrets > Actions):
#   AWS_ACCESS_KEY_ID       - IAM credentials with ECR + ECS + RDS + Terraform perms
#   AWS_SECRET_ACCESS_KEY
#   DB_PASSWORD             - RDS password (Terraform creates RDS with this password)
#
# All non-sensitive config (vpc_id, subnets, ecs_cluster_name, etc.) lives in
# infra/terraform/variables.tf with defaults. Edit that file to change infra config.

name: Deploy

on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Target environment"
        required: true
        default: "dev"
        type: choice
        options: [dev, staging, prod]
      skip_terraform:
        description: "Skip Terraform apply (images only)"
        required: false
        default: false
        type: boolean
      skip_build_push:
        description: "Skip Build & Push (use existing images; run only Deploy)"
        required: false
        default: false
        type: boolean
      image_tag_override:
        description: "Image tag when skipping build (e.g. b9929023 from a previous run)"
        required: false
        default: "latest"
        type: string

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: us-east-1
  TF_DIR: infra/terraform
  ECS_CLUSTER: sre-poc-mcp-cluster

jobs:
  # ────────────────────────────────────────────────────────────────────────────
  # 1. Build & push all Docker images to ECR
  # ────────────────────────────────────────────────────────────────────────────
  build-push:
    name: Build & Push Images
    runs-on: ubuntu-latest
    outputs:
      image_tag: ${{ steps.tag.outputs.tag || steps.tag-skip.outputs.tag }}
      affected_services: ${{ steps.compute-affected.outputs.affected_services || '[]' }}
      image_tag_previous: ${{ steps.restore-tag.outputs.tag || '' }}
    steps:
      - name: Set image tag (when skipping build)
        id: tag-skip
        if: ${{ inputs.skip_build_push }}
        run: echo "tag=${{ inputs.image_tag_override || 'latest' }}" >> "$GITHUB_OUTPUT"

      - uses: actions/checkout@v4
        if: ${{ !inputs.skip_build_push }}
        with:
          fetch-depth: 0

      - name: Set image tag
        id: tag
        if: ${{ !inputs.skip_build_push }}
        run: echo "tag=${GITHUB_SHA::8}" >> "$GITHUB_OUTPUT"

      - uses: actions/setup-node@v4
        if: ${{ !inputs.skip_build_push }}
        with:
          node-version: 20
          cache: npm

      - name: Install dependencies
        if: ${{ !inputs.skip_build_push }}
        run: npm ci

      - name: Configure AWS credentials
        if: ${{ !inputs.skip_build_push }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Restore previous image tag from S3
        id: restore-tag
        if: ${{ !inputs.skip_build_push && vars.TF_STATE_BUCKET != '' }}
        run: |
          PREV=$(aws s3 cp "s3://${{ vars.TF_STATE_BUCKET }}/rating-platform/${{ inputs.environment }}/last-image-tag" - 2>/dev/null || true)
          echo "tag=${PREV:-}" >> "$GITHUB_OUTPUT"

      - name: Login to ECR
        id: ecr-login
        if: ${{ !inputs.skip_build_push }}
        uses: aws-actions/amazon-ecr-login@v2

      - name: Create ECR repositories if missing
        if: ${{ !inputs.skip_build_push }}
        run: |
          REPOS=(
            rating-platform/core-rating
            rating-platform/line-rating
            rating-platform/product-config
            rating-platform/transform-service
            rating-platform/rules-service
            rating-platform/status-service
            rating-platform/rating-workspace
            rating-platform/adapter-kafka
            rating-platform/adapter-dnb
            rating-platform/adapter-gw
          )
          for repo in "${REPOS[@]}"; do
            aws ecr describe-repositories --repository-names "$repo" --region "${{ env.AWS_REGION }}" 2>/dev/null ||
            aws ecr create-repository --repository-name "$repo" --region "${{ env.AWS_REGION }}" --image-scanning-configuration scanOnPush=true --image-tag-mutability MUTABLE
          done

      - name: Compute affected services
        id: compute-affected
        if: ${{ !inputs.skip_build_push }}
        env:
          PREVIOUS_TAG: ${{ steps.restore-tag.outputs.tag }}
        run: |
          DEPLOYABLE="core-rating line-rating product-config transform-service rules-service status-service rating-workspace adapter-kafka adapter-dnb adapter-gw"
          AFFECTED=""
          if git rev-parse --verify origin/main >/dev/null 2>&1; then
            RAW=$(npx nx print-affected -t build --base=origin/main --head=HEAD --select=projects 2>/dev/null || true)
            if [ -n "$RAW" ]; then
              for p in $DEPLOYABLE; do
                if echo "$RAW" | grep -qE "\b$p\b"; then
                  AFFECTED="$AFFECTED $p"
                fi
              done
            fi
          fi
          # If base missing or no affected parsed, build all
          if [ -z "$AFFECTED" ]; then
            AFFECTED=$DEPLOYABLE
          fi
          # For Terraform: when no previous tag (first run / no S3), pass [] so TF uses single tag for all
          if [ -z "${PREVIOUS_TAG}" ]; then
            TF_AFFECTED="[]"
          else
            TF_AFFECTED="["
            first=true
            for p in $AFFECTED; do
              $first && first=false || TF_AFFECTED="$TF_AFFECTED,"
              TF_AFFECTED="$TF_AFFECTED\"$p\""
            done
            TF_AFFECTED="$TF_AFFECTED]"
          fi
          echo "affected_services=$TF_AFFECTED" >> "$GITHUB_OUTPUT"
          echo "$AFFECTED" | tr ' ' '\n' > affected.list
          echo "Affected: $AFFECTED"

      - name: Build and push affected images (parallel, 4 at a time)
        if: ${{ !inputs.skip_build_push }}
        env:
          ECR_REGISTRY: ${{ steps.ecr-login.outputs.registry }}
          IMAGE_TAG: ${{ steps.tag.outputs.tag }}
        run: |
          SERVICES=(
            "orchestrators/core-rating/Dockerfile:core-rating:rating-platform/core-rating"
            "orchestrators/line-rating/Dockerfile:line-rating:rating-platform/line-rating"
            "services/product-config/Dockerfile:product-config:rating-platform/product-config"
            "services/transform-service/Dockerfile:transform-service:rating-platform/transform-service"
            "services/rules-service/Dockerfile:rules-service:rating-platform/rules-service"
            "services/status-service/Dockerfile:status-service:rating-platform/status-service"
            "frontend/rating-workspace/Dockerfile:rating-workspace:rating-platform/rating-workspace"
            "services/adapters/kafka/Dockerfile:adapter-kafka:rating-platform/adapter-kafka"
            "services/adapters/dnb/Dockerfile:adapter-dnb:rating-platform/adapter-dnb"
            "services/adapters/gw/Dockerfile:adapter-gw:rating-platform/adapter-gw"
          )
          mapfile -t AFFECTED_LIST < <(tr -d '\r' < affected.list | grep -v '^$')
          build_one() {
            local entry="$1"
            local dockerfile nx_project ecr_name
            IFS=: read -r dockerfile nx_project ecr_name <<< "$entry"
            image_uri="${ECR_REGISTRY}/${ecr_name}:${IMAGE_TAG}"
            echo "::group::Build $nx_project"
            if [ "$nx_project" = "rating-workspace" ]; then
              npx nx run rating-workspace:build
            else
              npx nx run "$nx_project":build
              npx nx run "$nx_project":prune-lockfile 2>/dev/null || true
              npx nx run "$nx_project":copy-workspace-modules 2>/dev/null || true
            fi
            docker build -f "$dockerfile" -t "$image_uri" .
            docker push "$image_uri"
            echo "::endgroup::"
            echo "✓ $nx_project → $image_uri"
          }
          running=0
          for entry in "${SERVICES[@]}"; do
            IFS=: read -r _ nx_project _ <<< "$entry"
            if printf '%s\n' "${AFFECTED_LIST[@]}" | grep -qxF "$nx_project"; then
              build_one "$entry" &
              running=$((running + 1))
              if [ "$running" -ge 4 ]; then
                wait -n
                running=$((running - 1))
              fi
            fi
          done
          wait

  # ────────────────────────────────────────────────────────────────────────────
  # 2. Terraform plan + apply (deploys ECS); migrations run after apply when requested
  # ────────────────────────────────────────────────────────────────────────────
  deploy:
    name: Terraform Deploy
    needs: [build-push]
    if: |
      always() &&
      needs.build-push.result == 'success' &&
      inputs.skip_terraform != true
    runs-on: ubuntu-latest
    timeout-minutes: 25
    environment: ${{ inputs.environment || 'dev' }}
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.7"

      - name: Terraform init
        working-directory: ${{ env.TF_DIR }}
        env:
          TF_STATE_BUCKET: ${{ vars.TF_STATE_BUCKET }}
        run: |
          if [ -n "${TF_STATE_BUCKET}" ]; then
            echo "Using remote state in s3://${TF_STATE_BUCKET}"
            # Create bucket + DynamoDB table if they don't exist yet (idempotent bootstrap)
            aws s3api head-bucket --bucket "${TF_STATE_BUCKET}" 2>/dev/null || \
              aws s3api create-bucket --bucket "${TF_STATE_BUCKET}" --region "${{ env.AWS_REGION }}" && \
              aws s3api put-bucket-versioning --bucket "${TF_STATE_BUCKET}" \
                --versioning-configuration Status=Enabled && \
              aws s3api put-bucket-encryption --bucket "${TF_STATE_BUCKET}" \
                --server-side-encryption-configuration \
                '{"Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]}'
            aws dynamodb describe-table --table-name rating-platform-tfstate-locks --region "${{ env.AWS_REGION }}" 2>/dev/null || \
              aws dynamodb create-table \
                --table-name rating-platform-tfstate-locks \
                --attribute-definitions AttributeName=LockID,AttributeType=S \
                --key-schema AttributeName=LockID,KeyType=HASH \
                --billing-mode PAY_PER_REQUEST \
                --region "${{ env.AWS_REGION }}"
            terraform init -input=false \
              -backend-config="bucket=${TF_STATE_BUCKET}" \
              -backend-config="key=rating-platform/${{ inputs.environment || 'dev' }}/terraform.tfstate" \
              -backend-config="region=${{ env.AWS_REGION }}" \
              -backend-config="dynamodb_table=rating-platform-tfstate-locks" \
              -backend-config="encrypt=true"
          else
            echo "::warning::TF_STATE_BUCKET not set — using local state. Resources will be imported before apply. To persist state across runs, create an S3 bucket and set TF_STATE_BUCKET as a GitHub repository variable (Settings → Variables → Actions)."
            sed -i.bak 's|backend "s3" {}|backend "local" { path = "terraform.tfstate" }|' main.tf
            terraform init -input=false
          fi

      # Import resources that already exist in AWS but are absent from state.
      # This happens when TF_STATE_BUCKET is not set and local state is lost between runs.
      # Each import is best-effort (|| true) — safe to run on a fresh state or existing state.
      - name: Import existing AWS resources into state
        working-directory: ${{ env.TF_DIR }}
        env:
          TF_VAR_image_tag: ${{ needs.build-push.outputs.image_tag }}
          TF_VAR_image_tag_previous: ${{ needs.build-push.outputs.image_tag_previous }}
          TF_VAR_affected_services: ${{ needs.build-push.outputs.affected_services }}
          TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
          ENV: ${{ inputs.environment || 'dev' }}
        run: |
          # Safe import helper — skips if already in state, soft-fails if not in AWS
          tf_import() {
            local addr="$1" id="$2"
            if terraform state show "$addr" &>/dev/null 2>&1; then
              echo "  ✓ $addr already in state"
            else
              echo "  → Importing $addr"
              terraform import "$addr" "$id" && echo "  ✓ Done" || echo "  ⚠ Not found in AWS (will be created)"
            fi
          }

          # ── IAM Roles ────────────────────────────────────────────────────────
          tf_import "aws_iam_role.ecs_task_execution"     "rating-platform-ecs-exec-${ENV}"
          tf_import "aws_iam_role.ecs_task_default"       "rating-platform-ecs-task-${ENV}"
          tf_import "aws_iam_role.ecs_task_rules_service" "rating-platform-rules-svc-${ENV}"

          # ── CloudWatch Log Group ──────────────────────────────────────────────
          tf_import "aws_cloudwatch_log_group.ecs" "/ecs/rating-platform"

          # ── Security Groups (ALB + ECS tasks) ─────────────────────────────────
          VPC_ID=$(grep 'default.*vpc-' variables.tf | grep -o 'vpc-[a-z0-9]*' | head -1)
          SG_ALB=$(aws ec2 describe-security-groups \
            --filters "Name=group-name,Values=rating-platform-alb-${ENV}" "Name=vpc-id,Values=${VPC_ID}" \
            --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null || true)
          [ -n "$SG_ALB" ] && [ "$SG_ALB" != "None" ] && tf_import "aws_security_group.alb[0]" "$SG_ALB"
          SG_ECS=$(aws ec2 describe-security-groups \
            --filters "Name=group-name,Values=rating-platform-ecs-tasks-${ENV}" "Name=vpc-id,Values=${VPC_ID}" \
            --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null || true)
          [ -n "$SG_ECS" ] && [ "$SG_ECS" != "None" ] && tf_import "aws_security_group.ecs_tasks" "$SG_ECS"
          SG_RDS=$(aws ec2 describe-security-groups \
            --filters "Name=group-name,Values=rating-platform-rds-${ENV}" "Name=vpc-id,Values=${VPC_ID}" \
            --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null || true)
          [ -n "$SG_RDS" ] && [ "$SG_RDS" != "None" ] && tf_import "aws_security_group.rds[0]" "$SG_RDS"

          # ── ALB Target Groups (look up ARN by name) ───────────────────────────
          import_tg() {
            local name="$1" addr="$2"
            local arn
            arn=$(aws elbv2 describe-target-groups --names "$name" \
              --query 'TargetGroups[0].TargetGroupArn' --output text 2>/dev/null || true)
            [ -n "$arn" ] && [ "$arn" != "None" ] && tf_import "$addr" "$arn"
          }
          import_tg "rp-frontend-${ENV}"        "aws_lb_target_group.frontend[0]"
          import_tg "rp-core-rating-${ENV}"     "aws_lb_target_group.core_rating[0]"
          import_tg "rp-line-rating-${ENV}"     "aws_lb_target_group.line_rating[0]"
          import_tg "rp-product-config-${ENV}"  "aws_lb_target_group.product_config[0]"
          import_tg "rp-transform-${ENV}"       "aws_lb_target_group.transform_service[0]"
          import_tg "rp-rules-svc-${ENV}"       "aws_lb_target_group.rules_service[0]"
          import_tg "rp-status-svc-${ENV}"      "aws_lb_target_group.status_service[0]"

          # ── ALB (look up ARN by name) ─────────────────────────────────────────
          ALB_ARN=$(aws elbv2 describe-load-balancers --names "rating-platform-${ENV}" \
            --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null || true)
          [ -n "$ALB_ARN" ] && [ "$ALB_ARN" != "None" ] && tf_import "aws_lb.main[0]" "$ALB_ARN"

          # ── RDS DB Subnet Group ───────────────────────────────────────────────
          tf_import "aws_db_subnet_group.main[0]" "rating-platform-${ENV}"

          # ── Secrets Manager (look up ARN by name) ─────────────────────────────
          import_secret() {
            local name="$1" addr="$2"
            local arn
            arn=$(aws secretsmanager describe-secret --secret-id "$name" \
              --query 'ARN' --output text 2>/dev/null || true)
            [ -n "$arn" ] && [ "$arn" != "None" ] && tf_import "$addr" "$arn"
          }
          import_secret "rating-platform/aws-credentials" "aws_secretsmanager_secret.aws_credentials"
          import_secret "rating-platform/db-credentials"  "aws_secretsmanager_secret.db_credentials"

          # ── Service Discovery Namespace (import ID = NAMESPACE_ID:VPC_ID) ─────
          SD_NS=$(grep 'default.*rating-platform.local' variables.tf | grep -o 'rating-platform\.local' | head -1)
          NS_ID=$(aws servicediscovery list-namespaces \
            --query "Namespaces[?Name=='${SD_NS:-rating-platform.local}'].Id | [0]" \
            --output text 2>/dev/null || true)
          [ -n "$NS_ID" ] && [ "$NS_ID" != "None" ] && [ -n "$VPC_ID" ] && \
            tf_import "aws_service_discovery_private_dns_namespace.main" "${NS_ID}:${VPC_ID}"

      - name: Terraform plan
        working-directory: ${{ env.TF_DIR }}
        env:
          TF_VAR_image_tag: ${{ needs.build-push.outputs.image_tag }}
          TF_VAR_image_tag_previous: ${{ needs.build-push.outputs.image_tag_previous }}
          TF_VAR_affected_services: ${{ needs.build-push.outputs.affected_services }}
          TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
        run: terraform plan -input=false -out=tfplan

      - name: Terraform apply
        working-directory: ${{ env.TF_DIR }}
        env:
          TF_VAR_image_tag: ${{ needs.build-push.outputs.image_tag }}
          TF_VAR_image_tag_previous: ${{ needs.build-push.outputs.image_tag_previous }}
          TF_VAR_affected_services: ${{ needs.build-push.outputs.affected_services }}
          TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
        run: terraform apply -input=false -auto-approve tfplan

      - name: Save image tag to S3
        if: ${{ vars.TF_STATE_BUCKET != '' }}
        env:
          AFFECTED: ${{ needs.build-push.outputs.affected_services }}
          IMAGE_TAG: ${{ needs.build-push.outputs.image_tag }}
          IMAGE_TAG_PREV: ${{ needs.build-push.outputs.image_tag_previous }}
        run: |
          # After an affected-only build, only affected services have the new tag in ECR.
          # Next run's non-affected must use the tag that already exists for them → save that.
          if [ "$AFFECTED" = "[]" ] || [ -z "$AFFECTED" ]; then
            TAG_TO_SAVE="$IMAGE_TAG"
          else
            TAG_TO_SAVE="${IMAGE_TAG_PREV:-$IMAGE_TAG}"
          fi
          [ -n "$TAG_TO_SAVE" ] && echo -n "$TAG_TO_SAVE" | \
            aws s3 cp - "s3://${{ vars.TF_STATE_BUCKET }}/rating-platform/${{ inputs.environment || 'dev' }}/last-image-tag"

      - name: Force new deployment for all services
        run: |
          SERVICES=(
            core-rating line-rating product-config
            transform-service rules-service status-service
            rating-workspace adapter-kafka adapter-dnb adapter-gw
          )
          for svc in "${SERVICES[@]}"; do
            echo "Forcing deployment: $svc"
            aws ecs update-service \
              --cluster "${{ env.ECS_CLUSTER }}" \
              --service "$svc" \
              --force-new-deployment \
              --region "${{ env.AWS_REGION }}" \
              --no-cli-pager || true
          done

      - name: Show deploy info
        working-directory: ${{ env.TF_DIR }}
        run: |
          echo "───────────────────────────────────────────"
          echo "Deploy complete!"
          echo "Image tag:    ${{ needs.build-push.outputs.image_tag }}"
          echo "ECS Cluster:  $(terraform output -raw ecs_cluster_name 2>/dev/null || echo 'N/A')"
          echo "ALB DNS:      $(terraform output -raw alb_dns_name 2>/dev/null || echo 'N/A')"
          echo "───────────────────────────────────────────"

  # ────────────────────────────────────────────────────────────────────────────
  # 4. Smoke test — verify ECS services are healthy after deploy
  # ────────────────────────────────────────────────────────────────────────────
  smoke-test:
    name: Smoke Test
    needs: [build-push, deploy]
    if: needs.deploy.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Wait for ECS services to stabilize
        run: |
          SERVICES=(
            core-rating line-rating product-config
            transform-service rules-service status-service
            rating-workspace adapter-kafka adapter-dnb adapter-gw
          )
          echo "Waiting for services to reach RUNNING state..."
          for svc in "${SERVICES[@]}"; do
            echo -n "  $svc: "
            aws ecs wait services-stable \
              --cluster "${{ env.ECS_CLUSTER }}" \
              --services "$svc" \
              --region "${{ env.AWS_REGION }}" 2>/dev/null \
              && echo "STABLE" || echo "TIMEOUT (may still be deploying)"
          done

      - name: ECS service status
        run: |
          echo "── ECS Services ─────────────────────────────"
          aws ecs describe-services \
            --cluster "${{ env.ECS_CLUSTER }}" \
            --services \
              core-rating line-rating product-config \
              transform-service rules-service status-service \
              rating-workspace adapter-kafka adapter-dnb adapter-gw \
            --region "${{ env.AWS_REGION }}" \
            --query 'services[].{Name:serviceName,Status:status,Running:runningCount,Desired:desiredCount,TaskDef:taskDefinition}' \
            --output table --no-cli-pager
